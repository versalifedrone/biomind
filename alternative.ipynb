{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keVHmVHdQdLs"
   },
   "source": [
    "# Important: Modify the pynvrtc package as described in the following:\n",
    "https://github.com/loicland/superpoint_graph/issues/43#issuecomment-406928322"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchqrnn import QRNN, QRNNLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTciwxFkQdLt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, RNN, LSTM, GRU, Conv1d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIRECTORY = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zs6GLV1NQdLy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()\n",
    "\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_seqs = {str(i):[] for i in range(6)}\n",
    "with open(DATA_DIRECTORY+'train_filtered.txt','r') as fIn : \n",
    "    for line in fIn :\n",
    "        line = line.split(',')\n",
    "        id_seqs[line[1].strip()].append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1631\n",
      "2874\n"
     ]
    }
   ],
   "source": [
    "print(len(id_seqs['1'][0]))\n",
    "print(len(id_seqs['3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_0 = random.sample(id_seqs['0'],200)\n",
    "seq_3 = random.sample(id_seqs['3'],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_mini_0and3.txt','w') as fOut : \n",
    "    for seq in seq_0 : \n",
    "        fOut.write(seq + \",\" + \"0\\n\")\n",
    "    for seq in seq_3 : \n",
    "        fOut.write(seq + \",\" + \"3\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taking only 500 first nucleotids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIRECTORY+'train_filtered.txt','r') as fIn : \n",
    "    with open(DATA_DIRECTORY+'train_filtered_reduced.txt','w') as fOut : \n",
    "        for line in fIn : \n",
    "            line = line.split(',')\n",
    "            fOut.write(line[0][:1000] + \",\" + line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIRECTORY+'test_filtered.txt','r') as fIn : \n",
    "    with open(DATA_DIRECTORY+'test_filtered_reduced.txt','w') as fOut : \n",
    "        for line in fIn : \n",
    "            line = line.split(',')\n",
    "            fOut.write(line[0][:1000] + \",\" + line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIRECTORY+'val_filtered.txt','r') as fIn : \n",
    "    with open(DATA_DIRECTORY+'val_filtered_reduced.txt','w') as fOut : \n",
    "        for line in fIn : \n",
    "            line = line.split(',')\n",
    "            fOut.write(line[0][:1000] + \",\" + line[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlwv4O-oQdL1"
   },
   "source": [
    "# Torchtext dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tm9u1DvFQdL2"
   },
   "outputs": [],
   "source": [
    "#Initialize the two fields: Sequence and Class\n",
    "SEQ = data.Field(sequential=True,include_lengths=True, unk_token='N')\n",
    "LABEL = data.Field(sequential=False, unk_token='1') # is_target = True ?\n",
    "\n",
    "#train_set, validation_set, test_set = data.TabularDataset.splits(path='',\n",
    "#                                                                 train='train_mini_0and3.txt',\n",
    "#                                                                 validation='train_mini_0and3.txt',\n",
    "#                                                                 test='train_mini_0and3.txt', \n",
    "#                                                                 format = 'csv',\n",
    "#                                                                 fields=[('sequence', SEQ), ('label', LABEL)])\n",
    "\n",
    "train_set, validation_set, test_set = data.TabularDataset.splits(path='',\n",
    "                                                                 train=DATA_DIRECTORY+'train_filtered_reduced.txt',\n",
    "                                                                 validation=DATA_DIRECTORY+'val_filtered_reduced.txt',\n",
    "                                                                 test=DATA_DIRECTORY+'test_filtered_reduced.txt', \n",
    "                                                                 format = 'csv',\n",
    "                                                                 fields=[('sequence', SEQ), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6231,
     "status": "ok",
     "timestamp": 1543681846756,
     "user": {
      "displayName": "Lea Riera",
      "photoUrl": "",
      "userId": "09506228137911101216"
     },
     "user_tz": -60
    },
    "id": "yy8up8L-QdL6",
    "outputId": "06cb7283-ec3c-4f8c-dce1-5d793aad83da"
   },
   "outputs": [],
   "source": [
    "#L = [len(train_set[i].sequence) for i in range(len(train_set))]\n",
    "#plt.hist(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6224,
     "status": "ok",
     "timestamp": 1543681846758,
     "user": {
      "displayName": "Lea Riera",
      "photoUrl": "",
      "userId": "09506228137911101216"
     },
     "user_tz": -60
    },
    "id": "f5Pn8cI6QdL_",
    "outputId": "00c55434-0572-47cc-8923-ddf28d43f994"
   },
   "outputs": [],
   "source": [
    "#print('train_set.fields:', list(train_set.fields.keys()))\n",
    "#print('validation_set.fields:', list(validation_set.fields.keys()))\n",
    "#print('test_set.fields:', list(test_set.fields.keys()))\n",
    "#print()\n",
    "#print('size of training set', len(train_set))\n",
    "#print('size of validation set', len(validation_set))\n",
    "#print()\n",
    "#print('content of first training sample:')\n",
    "#print(vars(train_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FX65bqRlQdMD"
   },
   "outputs": [],
   "source": [
    "# build the vocabularies\n",
    "SEQ.build_vocab(train_set, min_freq=2) #NO unknows \n",
    "LABEL.build_vocab(train_set, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index()>,\n",
       "            {'N': 0, '<pad>': 1, 'G': 2, 'C': 3, 'A': 4, 'T': 5})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10161,
     "status": "ok",
     "timestamp": 1543681850711,
     "user": {
      "displayName": "Lea Riera",
      "photoUrl": "",
      "userId": "09506228137911101216"
     },
     "user_tz": -60
    },
    "id": "RUdIeFdjQdMG",
    "outputId": "f153fcce-be59-4e5f-c88b-f0b3088ea40b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text fields:\n",
      " size of vocabulary: 6\n",
      " no. times the \"N\" appear in the dataset: 57\n"
     ]
    }
   ],
   "source": [
    "print('Text fields:')\n",
    "print(' size of vocabulary:', len(SEQ.vocab))\n",
    "#print(\" vocabulary's embedding dimension:\", SEQ.vocab.vectors.size())\n",
    "print(' no. times the \"N\" appear in the dataset:', SEQ.vocab.freqs['N'])\n",
    "#print(\" list of vocabulary (int-to-str):\", SEQ.vocab.itos)\n",
    "#print(\" list of vocabulary (str-to-int):\", dict(SEQ.vocab.stoi))\n",
    "#print(SEQ.vocab.freqs)\n",
    "#print('\\nLabel fields:')\n",
    "#print('keys of LABEL.vocab:', list(LABEL.vocab.__dict__.keys()))\n",
    "#print(\" list of vocabulary (int-to-str):\", LABEL.vocab.itos)\n",
    "#print(\" list of vocabulary (str-to-int):\", dict(LABEL.vocab.stoi))\n",
    "#print(LABEL.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight = [i/sum(dic.values()) for i in dic.values()]\n",
    "#weight_square = [i**2 for i in weight]\n",
    "#weight_square = torch.FloatTensor(weight_square).cuda()\n",
    "#weight_square = 1 - weight_square/sum(weight_square)\n",
    "\n",
    "\n",
    "#final_weights = torch.FloatTensor([weight_square[int(i)] for i in LABEL.vocab.itos]).cuda()\n",
    "#print(final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ek4Eo9DUQdMP"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "train_iter = data.BucketIterator(train_set,\n",
    "                                 batch_size=BATCH_SIZE, \n",
    "                                 device=torch.device(\"cuda:0\" if use_cuda else \"cpu\"),\n",
    "                                 sort_key=lambda x: len(x.sequence), #Sorting within the batch\n",
    "                                 sort = True,\n",
    "                                 repeat = False\n",
    "                                )\n",
    "\n",
    "validation_iter = data.BucketIterator(validation_set,\n",
    "                                 batch_size=BATCH_SIZE, \n",
    "                                 device=torch.device(\"cuda:0\" if use_cuda else \"cpu\"),\n",
    "                                 sort_key=lambda x: len(x.sequence), #Sorting within the batch\n",
    "                                sort = True,\n",
    "                                repeat = False\n",
    "                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4457,
     "status": "ok",
     "timestamp": 1543840045364,
     "user": {
      "displayName": "Lea Riera",
      "photoUrl": "",
      "userId": "09506228137911101216"
     },
     "user_tz": -60
    },
    "id": "gqMzFHkbQdM1",
    "outputId": "d3f9d070-a4cd-4f11-b538-e82d55702537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "using cuda\n",
      "Net(\n",
      "  (embeddings): Embedding(6, 8)\n",
      "  (qrnn): QRNN(\n",
      "    (layers): ModuleList(\n",
      "      (0): QRNNLayer(\n",
      "        (linear): Linear(in_features=8, out_features=384, bias=True)\n",
      "      )\n",
      "      (1): QRNNLayer(\n",
      "        (linear): Linear(in_features=128, out_features=384, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=128, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# size of embeddings\n",
    "EMBEDDING_DIM = 8\n",
    "NUM_EMBEDDING = len(SEQ.vocab) #size of vocab \n",
    "NUM_CLASSES = len(LABEL.vocab.itos)\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS_LSTM = 1\n",
    "SEQ_LEN = len(train_set[0].sequence)\n",
    "print(SEQ_LEN)\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #learn a new embedding\n",
    "        self.embeddings = nn.Embedding(NUM_EMBEDDING, EMBEDDING_DIM)\n",
    "\n",
    "        # use pretrained embeddings\n",
    "        \n",
    "        #self.conv1 = Conv1d(in_channels= EMBEDDING_DIM,\n",
    "        #                    out_channels= CONV_CHANNELS,\n",
    "        #                    padding=0,\n",
    "        #                    kernel_size=1,\n",
    "        #                    stride=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.lstm = LSTM(input_size=EMBEDDING_DIM,\n",
    "        #                 hidden_size=HIDDEN_DIM,\n",
    "        #                 num_layers=NUM_LAYERS_LSTM,\n",
    "        #                 bidirectional=False)\n",
    "        \n",
    "        self.qrnn = QRNN(EMBEDDING_DIM, HIDDEN_DIM, num_layers=2)\n",
    "        self.qrnn.cuda()\n",
    "        \n",
    "        # link hidden to tag \n",
    "        self.linear = Linear(in_features=HIDDEN_DIM,\n",
    "                            out_features=NUM_CLASSES)\n",
    "        \n",
    "        \n",
    "        #init lstm hidden units \n",
    "        self.hidden = self.init_hidden(BATCH_SIZE)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sequences = x[0]\n",
    "        lengths = x[1]\n",
    "#         out = {}\n",
    "        batch_size = sequences.size()[1]\n",
    "        # get embeddings\n",
    "        x = self.embeddings(sequences)\n",
    "        #x = embeds.permute([1,2,0])\n",
    "        #c1 = F.relu(self.conv1(x))\n",
    "        #c2 = F.relu(self.conv2(x))\n",
    "        #c3 = F.relu(self.conv3(x))\n",
    "        #x = torch.cat((c1,c2,c3), 1)\n",
    "        #x = x.permute([2,0,1])\n",
    "        \n",
    "        #embeds = nn.utils.rnn.pack_padded_sequence(embeds,lengths/3, batch_first=False)\n",
    "        # rnn returns output and last hidden state\n",
    "        \n",
    "        _, x = self.qrnn(x)\n",
    "        #lstm_out, self.hidden = self.lstm(embeds)\n",
    "        #unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=False)\n",
    "        x = F.relu(x[-1].type(torch.float))\n",
    "        #last_output = self.dropout(last_output)\n",
    "        \n",
    "        freqs = F.softmax(self.linear(x))\n",
    "        return freqs\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(NUM_LAYERS_LSTM, BATCH_SIZE, HIDDEN_DIM),\n",
    "                torch.zeros(NUM_LAYERS_LSTM, BATCH_SIZE, HIDDEN_DIM))\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    print(\"using cuda\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1302,
     "status": "ok",
     "timestamp": 1543840050477,
     "user": {
      "displayName": "Lea Riera",
      "photoUrl": "",
      "userId": "09506228137911101216"
     },
     "user_tz": -60
    },
    "id": "wZwbtsNYQdM5",
    "outputId": "6a30afc3-9cb1-4fe8-b909-f5b917f3439c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings.weight': True,\n",
       " 'qrnn.layers.0.linear.weight': True,\n",
       " 'qrnn.layers.0.linear.bias': True,\n",
       " 'qrnn.layers.1.linear.weight': True,\n",
       " 'qrnn.layers.1.linear.bias': True,\n",
       " 'linear.weight': True,\n",
       " 'linear.bias': True}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which params require grad\n",
    "{p[0]: p[1].requires_grad for p in net.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoEQYT0TQdM9"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #weight = final_weights\n",
    "# we filter the model's parameters such that we can remove the embedding layer, \n",
    "# which does not have requires_grad\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001)\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = torch.eq(torch.max(ys, 1)[1], ts)\n",
    "#     print(torch.max(ys, 1)[1], ts)\n",
    "#     print(correct_prediction)\n",
    "    # averaging the one-hot encoded vector\n",
    "    return torch.mean(correct_prediction.float())\n",
    "\n",
    "def construct_sentences(batch):\n",
    "    return [\" \".join([SEQ.vocab.itos[elm] \n",
    "                      for elm in get_numpy(batch.sequence[:,i])])\n",
    "            for i in range(batch.sequence.size()[1])]\n",
    "\n",
    "def get_labels(batch):\n",
    "    return [LABEL.vocab.itos[get_numpy(batch.label[i])] for i in range(len(batch.label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41433600"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2011
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 774,
     "status": "error",
     "timestamp": 1543840061078,
     "user": {
      "displayName": "Lea Riera",
      "photoUrl": "",
      "userId": "09506228137911101216"
     },
     "user_tz": -60
    },
    "id": "7LxsaAH3QdNC",
    "outputId": "a9f861ee-5c40-44ec-ea54-da5eb846c414",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTrain 1.652\tVal 1.669\n",
      "Epoch 1\tTrain 1.650\tVal 1.671\n",
      "Epoch 2\tTrain 1.645\tVal 1.668\n",
      "Epoch 3\tTrain 1.640\tVal 1.667\n",
      "Epoch 4\tTrain 1.634\tVal 1.667\n",
      "Epoch 5\tTrain 1.635\tVal 1.666\n",
      "Epoch 6\tTrain 1.632\tVal 1.665\n",
      "Epoch 7\tTrain 1.633\tVal 1.665\n",
      "Epoch 8\tTrain 1.633\tVal 1.663\n",
      "Epoch 9\tTrain 1.632\tVal 1.662\n",
      "Epoch 10\tTrain 1.633\tVal 1.663\n",
      "Epoch 11\tTrain 1.629\tVal 1.663\n",
      "Epoch 12\tTrain 1.627\tVal 1.664\n",
      "Epoch 13\tTrain 1.623\tVal 1.662\n",
      "Epoch 14\tTrain 1.624\tVal 1.663\n",
      "Epoch 15\tTrain 1.621\tVal 1.664\n",
      "Epoch 16\tTrain 1.623\tVal 1.665\n",
      "Epoch 17\tTrain 1.619\tVal 1.665\n",
      "Epoch 18\tTrain 1.619\tVal 1.665\n",
      "Epoch 19\tTrain 1.617\tVal 1.665\n",
      "Epoch 20\tTrain 1.616\tVal 1.665\n",
      "Epoch 21\tTrain 1.614\tVal 1.665\n",
      "Epoch 22\tTrain 1.617\tVal 1.665\n",
      "Epoch 23\tTrain 1.616\tVal 1.662\n",
      "Epoch 24\tTrain 1.618\tVal 1.663\n",
      "Epoch 25\tTrain 1.623\tVal 1.664\n",
      "Epoch 26\tTrain 1.617\tVal 1.662\n",
      "Epoch 27\tTrain 1.613\tVal 1.660\n",
      "Epoch 28\tTrain 1.614\tVal 1.660\n",
      "Epoch 29\tTrain 1.611\tVal 1.659\n",
      "Epoch 30\tTrain 1.612\tVal 1.662\n",
      "Epoch 31\tTrain 1.615\tVal 1.662\n",
      "Epoch 32\tTrain 1.613\tVal 1.661\n",
      "Epoch 33\tTrain 1.615\tVal 1.663\n",
      "Epoch 34\tTrain 1.620\tVal 1.664\n",
      "Epoch 35\tTrain 1.613\tVal 1.660\n",
      "Epoch 36\tTrain 1.606\tVal 1.661\n",
      "Epoch 37\tTrain 1.604\tVal 1.661\n",
      "Epoch 38\tTrain 1.602\tVal 1.661\n",
      "Epoch 39\tTrain 1.608\tVal 1.660\n",
      "Epoch 40\tTrain 1.603\tVal 1.661\n",
      "Epoch 41\tTrain 1.602\tVal 1.661\n",
      "Epoch 42\tTrain 1.601\tVal 1.661\n",
      "Epoch 43\tTrain 1.599\tVal 1.662\n",
      "Epoch 44\tTrain 1.600\tVal 1.663\n",
      "Epoch 45\tTrain 1.600\tVal 1.661\n",
      "Epoch 46\tTrain 1.599\tVal 1.663\n",
      "Epoch 47\tTrain 1.595\tVal 1.664\n",
      "Epoch 48\tTrain 1.601\tVal 1.664\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "num_epoch = 500\n",
    "iter_by_epoch = int(len(train_set)/BATCH_SIZE)\n",
    "eval_every = 100\n",
    "\n",
    "reduced_train_lost = []\n",
    "reduced_train_accuracy = []\n",
    "\n",
    "reduced_val_lost = []\n",
    "reduced_val_accuracy = []\n",
    "\n",
    "train_loss, train_accs = [], []\n",
    "val_loss, val_accs = [], []\n",
    "\n",
    "epoch_index = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_loss, train_accs = [], []\n",
    "    val_loss, val_accs = [], []\n",
    "    \n",
    "    net.train()\n",
    "    # Training\n",
    "    for i, batch in enumerate(train_iter):\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(batch.sequence)\n",
    "        batch_loss = criterion(output, batch.label)\n",
    "\n",
    "        train_loss.append(get_numpy(batch_loss))\n",
    "        train_accs.append(get_numpy(accuracy(output, batch.label)))\n",
    "\n",
    "\n",
    "        if i % eval_every == 0:     \n",
    "            net.eval()\n",
    "            val_losses_running, val_accs_running, val_lengths = 0, 0, 0\n",
    "            \n",
    "            for val_batch in validation_iter:\n",
    "                output = net(val_batch.sequence)\n",
    "                val_losses_running += criterion(output, val_batch.label)*val_batch.batch_size\n",
    "                val_accs_running += accuracy(output, val_batch.label) *val_batch.batch_size\n",
    "                val_lengths += val_batch.batch_size\n",
    "\n",
    "            # divide by the total accumulated batch sizes\n",
    "            val_losses_running /= val_lengths\n",
    "            val_accs_running /= val_lengths\n",
    "            val_loss.append(get_numpy(val_losses_running))\n",
    "            val_accs.append(get_numpy(val_accs_running))\n",
    "            net.train()\n",
    "        \n",
    "        batch_loss.backward()     \n",
    "        optimizer.step()\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    reduced_train_lost.append(np.mean(train_loss))\n",
    "    reduced_train_accuracy.append(np.mean(train_accs))\n",
    "    \n",
    "    reduced_val_lost.append(np.mean(val_loss))\n",
    "    reduced_val_accuracy.append(np.mean(val_accs))\n",
    "    \n",
    "    epoch_index.append(epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch}\\tTrain {np.mean(train_loss):.3f}\\tVal {np.mean(val_loss):.3f}')\n",
    "    \n",
    "# 500, 20, 100/\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_index,reduced_train_lost,label='train_loss')\n",
    "plt.plot(epoch_inde\n",
    "         x,reduced_val_lost, label='valid_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_index, reduced_train_accuracy, label='train_accs')\n",
    "plt.plot(epoch_index, reduced_val_accuracy, label='valid_accs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(fig, format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_iter = [i - 112 for i in valid_iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_red = []\n",
    "little = []\n",
    "compt = 1\n",
    "for i in train_loss : \n",
    "    little.append(i)\n",
    "    if compt%100 == 0:\n",
    "        print(compt)\n",
    "        train_loss_red.append(np.mean(little))\n",
    "        little = []\n",
    "    compt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train_accs[:-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_red, label='train_loss')\n",
    "plt.plot(valid_iter, valid_loss, label='valid_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='train_accs')\n",
    "plt.plot(valid_iter, valid_accs, label='valid_accs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(output,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(17., device='cuda:0') 20\n",
      "tensor(19., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(19., device='cuda:0') 20\n",
      "tensor(19., device='cuda:0') 20\n",
      "tensor(19., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(19., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "tensor(20., device='cuda:0') 20\n",
      "[387] 400 tensor(387., device='cuda:0')\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embeddings): Embedding(6, 100)\n",
       "  (conv1): Conv1d(100, 100, kernel_size=(3,), stride=(3,))\n",
       "  (lstm): LSTM(100, 111)\n",
       "  (hidden2tag): Linear(in_features=111, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "val_losses, val_accs, val_lengths = 0, 0, 0\n",
    "predictions = []\n",
    "real_values = []\n",
    "for val_batch in train_iter:\n",
    "    output = net(val_batch.sequence)\n",
    "    predictions += [int(i) for i in torch.max(output,1)[1]]\n",
    "    real_values += [int(i) for i in val_batch.label]\n",
    "    val_losses += criterion(output, val_batch.label)*val_batch.batch_size\n",
    "    print(accuracy(output, val_batch.label) *val_batch.batch_size, val_batch.batch_size)\n",
    "    val_accs += accuracy(output, val_batch.label) *val_batch.batch_size\n",
    "    val_lengths += val_batch.batch_size\n",
    "\n",
    "print(\"[%i]\"%get_numpy(val_accs), val_lengths, val_accs)\n",
    "# divide by the total accumulated batch sizes\n",
    "val_losses /= val_lengths\n",
    "val_accs /= val_lengths\n",
    "valid_loss.append(get_numpy(val_losses))\n",
    "valid_accs.append(get_numpy(val_accs))\n",
    "print(\"[%i]\"%get_numpy(val_accs))\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3939e-07, 7.8227e-04, 9.9922e-01],\n",
       "        [1.1353e-06, 7.3812e-05, 9.9993e-01],\n",
       "        [8.5646e-06, 1.8252e-03, 9.9817e-01],\n",
       "        [6.4346e-06, 3.1196e-03, 9.9687e-01],\n",
       "        [2.4455e-04, 4.5467e-03, 9.9521e-01],\n",
       "        [4.9675e-06, 8.7108e-04, 9.9912e-01],\n",
       "        [1.5768e-05, 1.5943e-03, 9.9839e-01],\n",
       "        [1.4948e-04, 2.4624e-03, 9.9739e-01],\n",
       "        [1.3874e-05, 2.1734e-03, 9.9781e-01],\n",
       "        [2.4438e-06, 5.0490e-05, 9.9995e-01],\n",
       "        [3.6360e-06, 8.7438e-05, 9.9991e-01],\n",
       "        [1.6291e-05, 2.7198e-03, 9.9726e-01],\n",
       "        [1.5844e-05, 4.1070e-04, 9.9957e-01],\n",
       "        [6.0377e-06, 1.4313e-03, 9.9856e-01],\n",
       "        [7.8869e-06, 1.8403e-03, 9.9815e-01],\n",
       "        [1.8819e-05, 1.8621e-03, 9.9812e-01],\n",
       "        [1.2744e-05, 1.2774e-04, 9.9986e-01],\n",
       "        [4.6169e-06, 4.3788e-03, 9.9562e-01],\n",
       "        [1.7736e-05, 1.7656e-03, 9.9822e-01],\n",
       "        [1.4403e-05, 8.0118e-05, 9.9991e-01]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ nan  nan  nan]\n",
      " [0.01 0.97 0.02]\n",
      " [0.01 0.02 0.96]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(real_values, predictions)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "classes = [str(i) for i in range(NUM_CLASSES)]\n",
    "plot_confusion_matrix(cnf_matrix, classes,\n",
    "                      title='Confusion matrix, without normalization', normalize=True)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def get_gpu_memory_map():\n",
    "    \"\"\"Get the current gpu usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    usage: dict\n",
    "        Keys are device ids as integers.\n",
    "        Values are memory usage as integers in MB.\n",
    "    \"\"\"\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ], encoding='utf-8')\n",
    "    # Convert lines into a dictionary\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "    return gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6647}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu_memory_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1544748126.33426, 1544762510.6079597]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14384.273699760437"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times[0][1]-times[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.37578702,\n",
       "  0.3783192,\n",
       "  0.3818779,\n",
       "  0.38201478,\n",
       "  0.38550505,\n",
       "  0.38988504,\n",
       "  0.39255407,\n",
       "  0.3933753,\n",
       "  0.39474404,\n",
       "  0.39693403,\n",
       "  0.39782372,\n",
       "  0.39713934,\n",
       "  0.39590746,\n",
       "  0.39590746,\n",
       "  0.3963181,\n",
       "  0.39679715,\n",
       "  0.40049276,\n",
       "  0.40213522,\n",
       "  0.4000137,\n",
       "  0.40069807,\n",
       "  0.39994526,\n",
       "  0.40145087,\n",
       "  0.4011771,\n",
       "  0.39980838,\n",
       "  0.39789215,\n",
       "  0.39871338,\n",
       "  0.3994662,\n",
       "  0.3993293,\n",
       "  0.39994526,\n",
       "  0.3998768,\n",
       "  0.40090337,\n",
       "  0.40192991,\n",
       "  0.4024774,\n",
       "  0.40124556,\n",
       "  0.4009718,\n",
       "  0.40213522,\n",
       "  0.40192991,\n",
       "  0.40275118,\n",
       "  0.40275118,\n",
       "  0.4018615,\n",
       "  0.402409,\n",
       "  0.4009718,\n",
       "  0.40254584,\n",
       "  0.40275118,\n",
       "  0.40124556,\n",
       "  0.40179303,\n",
       "  0.40329865,\n",
       "  0.40384614,\n",
       "  0.4018615,\n",
       "  0.4029565,\n",
       "  0.40165618,\n",
       "  0.40364084,\n",
       "  0.4046674,\n",
       "  0.40569395,\n",
       "  0.40658364,\n",
       "  0.40630987,\n",
       "  0.40658364,\n",
       "  0.40418833,\n",
       "  0.40555707,\n",
       "  0.40548864,\n",
       "  0.40507802,\n",
       "  0.40192991,\n",
       "  0.4022721,\n",
       "  0.40268272,\n",
       "  0.40158772,\n",
       "  0.40165618,\n",
       "  0.4028196,\n",
       "  0.40583083,\n",
       "  0.40569395,\n",
       "  0.4033671,\n",
       "  0.40329865,\n",
       "  0.40192991,\n",
       "  0.40138242,\n",
       "  0.40158772,\n",
       "  0.4018615,\n",
       "  0.399124,\n",
       "  0.40439364,\n",
       "  0.40418833,\n",
       "  0.40234053,\n",
       "  0.4022721,\n",
       "  0.40364084,\n",
       "  0.40275118,\n",
       "  0.4030249,\n",
       "  0.40254584,\n",
       "  0.40254584,\n",
       "  0.40377772,\n",
       "  0.40535176,\n",
       "  0.40569395,\n",
       "  0.4029565,\n",
       "  0.402409,\n",
       "  0.40514645,\n",
       "  0.40432522,\n",
       "  0.40617302,\n",
       "  0.4054202,\n",
       "  0.40487272,\n",
       "  0.40377772,\n",
       "  0.40459895,\n",
       "  0.4046674,\n",
       "  0.40507802,\n",
       "  0.4044621]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.36340585,\n",
       "  0.36293897,\n",
       "  0.3634642,\n",
       "  0.36418396,\n",
       "  0.36482593,\n",
       "  0.36550683,\n",
       "  0.36614877,\n",
       "  0.36769208,\n",
       "  0.36741325,\n",
       "  0.3669464,\n",
       "  0.36734837,\n",
       "  0.36718628,\n",
       "  0.36620715,\n",
       "  0.3667583,\n",
       "  0.36644703,\n",
       "  0.36312053,\n",
       "  0.3619663,\n",
       "  0.36278334,\n",
       "  0.36162266,\n",
       "  0.36195982,\n",
       "  0.36157078,\n",
       "  0.36190146,\n",
       "  0.36127898,\n",
       "  0.36157724,\n",
       "  0.3614735,\n",
       "  0.36199874,\n",
       "  0.36178476,\n",
       "  0.3625434,\n",
       "  0.36158374,\n",
       "  0.3623035,\n",
       "  0.3618885,\n",
       "  0.36120117,\n",
       "  0.36275744,\n",
       "  0.3623748,\n",
       "  0.36251745,\n",
       "  0.36203116,\n",
       "  0.3629844,\n",
       "  0.36260828,\n",
       "  0.36231,\n",
       "  0.3622257,\n",
       "  0.3628871,\n",
       "  0.36282876,\n",
       "  0.36166155,\n",
       "  0.36226463,\n",
       "  0.3631011,\n",
       "  0.3630622,\n",
       "  0.36136976,\n",
       "  0.36256933,\n",
       "  0.36101308,\n",
       "  0.36223868,\n",
       "  0.36149293,\n",
       "  0.36190146,\n",
       "  0.36169398,\n",
       "  0.36216736,\n",
       "  0.36273146,\n",
       "  0.3625499,\n",
       "  0.36271852,\n",
       "  0.36505938,\n",
       "  0.36133087,\n",
       "  0.3623878,\n",
       "  0.3619728,\n",
       "  0.3665054,\n",
       "  0.36409968,\n",
       "  0.3643331,\n",
       "  0.36531228,\n",
       "  0.366674,\n",
       "  0.36124006,\n",
       "  0.36245915,\n",
       "  0.36338642,\n",
       "  0.36578566,\n",
       "  0.366071,\n",
       "  0.36672586,\n",
       "  0.36698523,\n",
       "  0.36362633,\n",
       "  0.36171344,\n",
       "  0.36498156,\n",
       "  0.36306867,\n",
       "  0.36135033,\n",
       "  0.36236838,\n",
       "  0.3656365,\n",
       "  0.36264715,\n",
       "  0.36409324,\n",
       "  0.3650983,\n",
       "  0.3621414,\n",
       "  0.36548737,\n",
       "  0.36450818,\n",
       "  0.3608575,\n",
       "  0.36070186,\n",
       "  0.3628871,\n",
       "  0.362498,\n",
       "  0.36367172,\n",
       "  0.3631919,\n",
       "  0.3632373,\n",
       "  0.36334103,\n",
       "  0.36301032,\n",
       "  0.36394408,\n",
       "  0.36444333,\n",
       "  0.36371714,\n",
       "  0.3638857,\n",
       "  0.3636393]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1544781035.925805"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torchtext_dataloader.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
